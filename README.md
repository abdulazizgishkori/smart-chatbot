# ğŸ¤– Smart Chatbot using Streamlit + Local AI

A powerful, privacy-friendly AI chatbot built with [Streamlit](https://streamlit.io) and local LLMs using [Ollama](https://ollama.com). It supports markdown formatting, emoji reactions, multilingual conversation, PDF Q&A, and much more â€” all running locally on your machine!

---

## ğŸš€ Features

- ğŸ’¬ Chat with a local LLM (via Ollama)
- ğŸ“ Supports Markdown formatting & emoji reactions
- ğŸŒ Multilingual conversations
- ğŸ”’ Optional authentication (Streamlit Auth or Firebase)
- ğŸ¤ Audio chat support (TTS + STT)
- ğŸ“„ PDF, TXT & Markdown Q&A
- ğŸ“Š CSV upload and chat
- ğŸ–¼ï¸ Image drag-and-drop + captioning
- ğŸ§  Smart memory (session-aware chat)
- ğŸŒ™ Light/Dark mode toggle
- â¬‡ï¸ Export chat as `.txt`, `.md`, `.pdf`

---

## ğŸ“ Folder Structure


---

## ğŸ§  Powered by Local LLM

Uses [Ollama](https://ollama.com) to run local language models like:

- `llama3`
- `mistral`
- `gemma`
- or any custom GGUF/GGML model

You have full control. No external APIs required.

---

## âš™ï¸ Installation

### 1. Clone the Repo

```bash
git clone https://github.com/abdulazizgishkori/smart-chatbot.git
cd smart-chatbot
# Create a virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt
ollama run llama3streamlit run app.py



